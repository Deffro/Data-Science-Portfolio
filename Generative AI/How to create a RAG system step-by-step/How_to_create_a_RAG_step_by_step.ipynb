{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://github.com/Deffro/Data-Science-Portfolio/tree/master\"><img src=\"https://img.shields.io/badge/GitHub%20Repository-black?logo=github\"></a>\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/13PSwmgbQwpcXDIVGCZrvbpZNK7VngNk5?usp=sharing)"
      ],
      "metadata": {
        "id": "UQXvxmoMmjto"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building a Retrieval-Augmented Generation (RAG) System with NVIDIA's Annual Financial Statement**\n",
        "\n",
        "In this tutorial, we’ll explore the creation of a **Retrieval-Augmented Generation (RAG) system** using NVIDIA's latest 10-K filing as our data source.\n",
        "\n",
        "RAG combines **retrieval** and **generation** to deliver factual, context-driven answers from a given dataset. This approach ensures that the responses are grounded in the provided information, minimizing hallucinations often associated with language models.\n",
        "\n",
        "By the end of this tutorial, we will have built a pipeline that:\n",
        "1. Downloads and processes real-world financial data from the SEC EDGAR database.\n",
        "2. Splits and chunks the data for efficient retrieval.\n",
        "3. Embeds the chunks into a high-dimensional space for similarity search using FAISS.\n",
        "4. Retrieves relevant information for a given query.\n",
        "5. Generates a coherent and accurate answer using a Large Language Model (LLM).\n",
        "\n",
        "### **Why RAG?**\n",
        "It's deal for tasks like:\n",
        "\n",
        "- Summarizing company reports.\n",
        "- Providing contextual answers to domain-specific questions.\n",
        "- Enabling users to \"chat with their data.\"\n",
        "\n",
        "### **Tutorial Overview**\n",
        "We’ll use NVIDIA’s latest **10-K filing** from the SEC as our dataset. Here's what we’ll cover:\n",
        "1. **Data Acquisition**: How to fetch the latest 10-K filing directly from the SEC EDGAR database.\n",
        "2. **Data Preprocessing**: Splitting the content into manageable chunks with overlapping context.\n",
        "3. **Embedding and Indexing**: Leveraging **sentence-transformers** for embeddings and **FAISS** for efficient similarity search.\n",
        "4. **Querying the Data**: Retrieving relevant chunks for user queries.\n",
        "5. **Grounded Generation**: Using a pre-trained LLM to generate answers based on the retrieved information.\n"
      ],
      "metadata": {
        "id": "-_XNY0hqAhb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers faiss-gpu==1.7.2 sentence-transformers==3.0.1"
      ],
      "metadata": {
        "id": "c1noxcF8l2JP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the latest NVIDIA Annual Financial Statement"
      ],
      "metadata": {
        "id": "auvhGryCnfHr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HpD07ZphIOG",
        "outputId": "ffdaead0-c837-42c1-bafb-78e0fa3e5d69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0001045810-24-000029.txt : 20240221 0001045810-24-000029.hdr.sgml : 20240221 20240221163657\n",
            "ACCESSION NUMBER:\t\t0001045810-24-000029\n",
            "CONFORMED SUBMISSION TYPE:\t10-K\n",
            "PUBLIC DOCUMENT COUNT:\t\t114\n",
            "CONFORMED PERIOD OF REPORT:\t20240128\n",
            "FILED AS OF DATE:\t\t20240221\n",
            "DATE AS OF CHANGE:\t\t20240221\n",
            "\n",
            "FILER:\n",
            "\n",
            "\tCOMPANY DATA:\t\n",
            "\t\tCOMPANY CONFORMED NAME:\t\t\tNVIDIA CORP\n",
            "\t\tCENTRAL INDEX KEY:\t\t\t0001045810\n",
            "\t\tSTANDARD INDUSTRIAL CLASSIFICATION:\tSEMICONDUCTORS & RELATED DEVICES [3674]\n",
            "\t\tORGANIZATION NAME:           \t04 Manufacturing\n",
            "\t\tIRS NUMBER:\t\t\t\t943177549\n",
            "\t\tSTATE OF INCORPORATION:\t\t\tDE\n",
            "\t\tFISCAL YEAR END:\t\t\t0128\n",
            "\n",
            "\tFILING VALUES:\n",
            "\t\tFORM TYPE:\t\t10-K\n",
            "\t\tSEC ACT:\t\t1934 Act\n",
            "\t\tSEC FILE NUMBER:\t000-23985\n",
            "\t\tFILM NUMBER:\t\t24660316\n",
            "\n",
            "\tBUSINESS ADDRESS:\t\n",
            "\t\tSTREET 1:\t\t2788 SAN TOMAS EXPRESSWAY\n",
            "\t\tCITY:\t\t\tSANTA CLARA\n",
            "\t\tSTATE:\t\t\tCA\n",
            "\t\tZIP:\t\t\t95051\n",
            "\t\tBUSINESS PHONE:\t\t408-486-2000\n",
            "\n",
            "\tMAIL ADDRESS:\t\n",
            "\t\tSTREET 1:\t\t2788 SAN TOMAS EXPRESSWAY\n",
            "\t\tCITY:\t\t\tSANTA CLARA\n",
            "\t\tSTATE:\t\t\tCA\n",
            "\t\tZIP:\t\t\t95051\n",
            "\n",
            "\tFORMER COMPANY:\t\n",
            "\t\tFORMER CONFORMED NAME:\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def get_latest_10k_text(cik):\n",
        "    \"\"\"\n",
        "    Fetches the latest 10-K filing for a given company CIK and returns the content as a single text.\n",
        "\n",
        "    Parameters:\n",
        "    - cik (str): CIK number of the company.\n",
        "\n",
        "    Returns:\n",
        "    - str: Text content of the latest 10-K filing.\n",
        "    \"\"\"\n",
        "    # Step 1: Get the filing index from SEC EDGAR\n",
        "    base_url = \"https://data.sec.gov/submissions/\"\n",
        "    headers = {\"User-Agent\": \"YourName Contact@Email.com\"}\n",
        "\n",
        "    # Fetch the company's filing index\n",
        "    response = requests.get(f\"{base_url}CIK{cik}.json\", headers=headers)\n",
        "    response.raise_for_status()\n",
        "    data = response.json()\n",
        "\n",
        "    # Step 2: Find the latest 10-K filing\n",
        "    filings = data[\"filings\"][\"recent\"]\n",
        "    for i, form_type in enumerate(filings[\"form\"]):\n",
        "        if form_type == \"10-K\":\n",
        "            accession_number = filings[\"accessionNumber\"][i].replace(\"-\", \"\")\n",
        "            file_url = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{accession_number}/index.json\"\n",
        "            break\n",
        "    else:\n",
        "        raise ValueError(\"No 10-K filings found for the given CIK.\")\n",
        "\n",
        "    # Step 3: Get the document URL from the filing index\n",
        "    filing_response = requests.get(file_url, headers=headers)\n",
        "    filing_response.raise_for_status()\n",
        "    filing_data = filing_response.json()\n",
        "\n",
        "    # Locate the primary document (usually ending with \".htm\" or \".txt\")\n",
        "    primary_doc = None\n",
        "    for doc in filing_data[\"directory\"][\"item\"]:\n",
        "        if doc[\"name\"].endswith(\".htm\") or doc[\"name\"].endswith(\".txt\"):\n",
        "            primary_doc = doc[\"name\"]\n",
        "            break\n",
        "\n",
        "    if not primary_doc:\n",
        "        raise ValueError(\"Could not locate primary document in filing.\")\n",
        "\n",
        "    # Step 4: Fetch the primary document\n",
        "    filing_url = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{accession_number}/{primary_doc}\"\n",
        "    filing_content = requests.get(filing_url, headers=headers).text\n",
        "\n",
        "    # Step 5: Parse and clean up the content\n",
        "    soup = BeautifulSoup(filing_content, \"html.parser\")\n",
        "    text_content = soup.get_text(separator=\" \", strip=True)\n",
        "\n",
        "    return text_content\n",
        "\n",
        "# Example: Fetch NVIDIA's latest 10-K\n",
        "cik = \"0001045810\"  # CIK for NVIDIA\n",
        "try:\n",
        "    latest_10k_text = get_latest_10k_text(cik)\n",
        "    print(latest_10k_text[:1000])  # Print the first 1000 characters for brevity\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will only keep Item 1 and Item 1A to use for this project."
      ],
      "metadata": {
        "id": "QQDDsPte-93F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latest_10k_text = latest_10k_text[30332:185600]"
      ],
      "metadata": {
        "id": "MRT0Gyghq2tB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1. Splitting the text into chunks"
      ],
      "metadata": {
        "id": "eMBzkIIRnsXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all let's split the text and create a list of all sentences."
      ],
      "metadata": {
        "id": "s0_bDNZkoL5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the text into sentences\n",
        "sentences = [sentence.strip() for sentence in latest_10k_text.split('.') if sentence.strip()]"
      ],
      "metadata": {
        "id": "j-7cXO_poK1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEAkXdWNoVFb",
        "outputId": "8e1cdfa4-547a-4b4b-be18-e2b09c8d3b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "878"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got 878 sentences if splitting by the character \".\""
      ],
      "metadata": {
        "id": "7siPd1kQob1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use these sentences as is to create chunks, but we will use **overlapping chunks**\n",
        "\n",
        "When processing text for retrieval systems, ensuring that no critical information is lost is essential.\n",
        "This is especially important for documents where ideas and facts often span multiple sentences or sections.\n",
        "\n",
        "A technique called **overlapping chunks** can help maintain contextual continuity and relevance.\n",
        "\n",
        "Overlapping chunks include a portion of sentences from the surrounding text, ensuring that the boundaries of each chunk retain context from adjacent parts. This approach minimizes the loss of meaning that can occur when splitting text into discrete sections.\n",
        "\n",
        "For instance, if we divide text into chunks of three sentences with an overlap of one sentence:\n",
        "- **Chunk 1**: Sentences 1, 2, 3\n",
        "- **Chunk 2**: Sentences 3, 4, 5\n",
        "- **Chunk 3**: Sentences 5, 6, 7\n",
        "\n",
        "Notice that each chunk shares some sentences with the previous one, which improves context and ensures that no vital information is left out.\n",
        "\n",
        "---\n",
        "\n",
        "### **Advantages of Overlapping Chunks**\n",
        "\n",
        "1. **Improved Context**: By overlapping sentences, each chunk carries forward important information from its predecessor, creating a seamless flow of ideas.\n",
        "   \n",
        "2. **Reduced Fragmentation**: Critical information located at the edges of chunks is retained, reducing the risk of incomplete or inaccurate retrieval.\n",
        "   \n",
        "3. **Higher Relevance**: Overlapping ensures that relevant information is less likely to be excluded during query processing, resulting in more accurate results.\n",
        "\n"
      ],
      "metadata": {
        "id": "0HKWsvaTBQh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_sentences_with_context(sentences, sentences_per_chunk=3, overlap=1):\n",
        "    \"\"\"\n",
        "    Chunk sentences into groups with overlap for context.\n",
        "\n",
        "    Parameters:\n",
        "    - sentences (list): A list of sentences.\n",
        "    - sentences_per_chunk (int): The number of sentences per chunk.\n",
        "    - overlap (int): The number of sentences that should overlap between chunks.\n",
        "\n",
        "    Returns:\n",
        "    - list: A list of overlapping chunks.\n",
        "    \"\"\"\n",
        "    chunks = []\n",
        "    for i in range(0, len(sentences), sentences_per_chunk - overlap):\n",
        "        chunk = sentences[i:i + sentences_per_chunk]\n",
        "        chunks.append(' '.join(chunk))\n",
        "        # Break if we've reached the end of the list\n",
        "        if i + sentences_per_chunk >= len(sentences):\n",
        "            break\n",
        "    return chunks\n",
        "\n",
        "# Specify the number of sentences per chunk and overlap\n",
        "sentences_per_chunk = 10\n",
        "overlap = 2\n",
        "texts = chunk_sentences_with_context(sentences, sentences_per_chunk, overlap)"
      ],
      "metadata": {
        "id": "0LX_iKaTjS1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see the 3rd chunk:"
      ],
      "metadata": {
        "id": "WYwab37NB9VL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "1vymfondo5VM",
        "outputId": "c5cbc8d7-8e3b-4bc7-af76-9ba64df26302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'We have invested over $45 3 billion in research and development since our inception, yielding inventions that are essential to modern computing Our invention of the GPU in 1999 sparked the growth of the PC gaming market and redefined computer graphics With our introduction of the CUDA programming model in 2006, we opened the parallel processing capabilities of our GPU to a broad range of compute-intensive applications, paving the way for the emergence of modern AI In 2012, the AlexNet neural network, trained on NVIDIA GPUs, won the ImageNet computer image recognition competition, marking the “Big Bang” moment of AI We introduced our first Tensor Core GPU in 2017, built from the ground-up for the new era of AI, and our first autonomous driving system-on-chips, or SoC, in 2018 Our acquisition of Mellanox in 2020 expanded our innovation canvas to include networking and led to the introduction of a new processor class – the data processing unit, or DPU Over the past 5 years, we have built full software stacks that run on top of our GPUs and CUDA to bring AI to the world’s largest industries, including NVIDIA DRIVE stack for autonomous driving, Clara for healthcare, and Omniverse for industrial digitalization; and introduced the NVIDIA AI Enterprise software – essentially an operating system for enterprise AI applications In 2023, we introduced our first data center CPU, Grace, built for giant-scale AI and high-performance computing With a strong engineering culture, we drive fast, yet harmonized, product and technology innovations in all dimensions of computing including silicon, systems, networking, software and algorithms'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Convert chunks to embeddings"
      ],
      "metadata": {
        "id": "B67kuJvcp8lR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "After creating chunks of text, the next step is to convert these chunks into numerical representations called **embeddings**. These embeddings are essential for enabling similarity-based search and retrieval tasks.\n",
        "\n",
        "---\n",
        "\n",
        "### **What Are Embeddings?**\n",
        "\n",
        "Embeddings are dense vector representations of text in a high-dimensional space. They capture the semantic meaning of text, making it possible to compare and retrieve chunks based on their contextual similarity rather than just matching keywords.\n",
        "\n",
        "For instance:\n",
        "- Sentences like \"The dog barked loudly.\" and \"A loud noise was made by the dog.\" may have similar embeddings despite using different words.\n",
        "- This semantic understanding is crucial for retrieval systems to find relevant results.\n",
        "\n",
        "---\n",
        "\n",
        "### **Embedding Model**\n",
        "\n",
        "To generate embeddings, we use the **`sentence-transformers`** library and the `all-mpnet-base-v2` model, which is well-suited for capturing semantic relationships in text. This model outputs a fixed-dimensional embedding (768 dimensions) for each input text.\n"
      ],
      "metadata": {
        "id": "S1FzmhYYCIG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load SentenceTransformer model\n",
        "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "\n",
        "# Convert chunks to embeddings\n",
        "embeds = model.encode(texts, show_progress_bar=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505,
          "referenced_widgets": [
            "a4ad64788b424c35a58d801989813124",
            "ceb625233c02471193514467f99fa6f7",
            "2fa44c76947e481f9b88e2ee7af49b79",
            "826d8e7bd9964ba9bc635c176b6baf62",
            "085d304791ec480e8e73d87da5741c1e",
            "ba12685a071f4c83b01b9a5a10305fa0",
            "0f9491f9481e47438a54f1aa2cf7c280",
            "69f1e32bfb26441a8b320910b1019259",
            "ce7ce532c4c24e9b895dc46e8d50f83f",
            "653063d7c35b4067a9c09d31656f5fae",
            "c57f1e8a603949d2bd89d39a5926dfbe",
            "3f0df9561efc44b8a7b11ca88b60935a",
            "f13ec87e5ce740efa54f1e5856005e53",
            "aed11ab71da34c91a2d071f0b151ec96",
            "f5528dd169384111b2852e91c25fcdba",
            "14bf373462944760be2e0a9dc1e98d3d",
            "0cb49bc8c57f4629b0b1b8bc9d600baa",
            "e7a9e75697174770886f712c1a168192",
            "226278d9cc0d45488b0620eeeeac2e3a",
            "67f58248ef604d72ae34730adf07532e",
            "9ffebbff92fe4a2c99a1a7ed46ed7d75",
            "eddf81dbaab04778aadec81865434bc4",
            "81274dc6dea043669e193dc1bee572ea",
            "9d9087d3616b42a38ee37561304493e0",
            "feaaedd4aaf04474b12c0b5f3a43500a",
            "70902bebc5254eafa567c19806f587e8",
            "41fc6050c5e546fab6dd06a182ea0bef",
            "af8624c044424017a5527698eb58a808",
            "c1d7169d79f44b2ca1108d3959caf2d0",
            "cb1475636f5b43e28c2c481c46e8a66f",
            "f77b81ac15214b90b675e7d9e5854f2b",
            "e83949b4063b4618b101e1ea7973e9bc",
            "f3546a3b12244684b102ba612169bbd0",
            "2d813837fae64d0abe3eb5705b1108f8",
            "87334f07abe341c89d9bc17814d660ec",
            "cd69b375ceb440e8bf11c1c4b25d099d",
            "f0e21e65f70449709ae9f2925afd751e",
            "06a2cd0a22bb4a92956376297be47647",
            "024be8a5be874a3f82b6589bd94ecc9f",
            "df5d4babba0544608c832e8ae7e2cad7",
            "b3c232140222481a8dc3588db5b4cd4b",
            "77c5a8bbdbcd4303a594785711445d7e",
            "743b8489eae044afb874938da230c536",
            "b5e1c8643e164370b7afda074084deda",
            "3a2aa298d480467091028bfd137d4efb",
            "65126f9c026e451cb2ebb03b728de5ab",
            "eda7552e1c594b2fa2360e08129fb1ab",
            "300fa59a4e20460380435a31de232b55",
            "eb9480aeb7764e0e942ee5e99a9afd0e",
            "338c875994bf458c9dd1d0253fe0613d",
            "09b5c07018f341b3ae01e9d9dcfa00bd",
            "28e623dd43d8455ebca976b9d9fe8136",
            "a18edec129a3401ebf42ff5ab2bdf286",
            "2b9742118c2443e5ad97a6f17d72ebff",
            "1609c7abec6b44a1bdcdae9e777deaa2",
            "90606bb87e024f85aef388757ba549c7",
            "0b37ac36a81b4baba926589b4b798b6e",
            "81e6cf369d7041778273162f875623d7",
            "9a94acbdfb9a442a92878e707d71a384",
            "afa1b29f87bb442baece016ad33720ce",
            "68d48c16d49946459f1e8df8009b2226",
            "d5514ab92b7049ecb04ac9e30f9f0439",
            "e25cb36dca6e4adcb6d4dc9297195e7f",
            "6706a4ca5f2b4818ae9598268d91576a",
            "a525ded8c13640bcb3bd235e2a3d58bf",
            "d7b1d8e01cf14be79fc037e9748e149d",
            "1fa6df61dc6d4c4ab8a3cf684785dc2c",
            "311fb1df94074e11bd1bed69bcd6bba0",
            "1d9546724a13450a83f2656627d57784",
            "2b97fd0e474d425587036621361e4fe8",
            "9d6c6b9575fd4088b070b17ee60b7909",
            "bc122b4176404c4a8807c25cab25d30d",
            "a2e735177ffb44ee862fd692995f8256",
            "e00ae52bf22243e78a90c1e049756eb8",
            "c8c78910011f4679bd546a618f7727a1",
            "68b45d2b8c254006ad741c22efde1a6e",
            "c43b5bf4c0bd4e9fbf79ed9f643912b7",
            "9e52e954bb034fb4a9f32c4ea8920ae0",
            "28d2f325e40541cbac6cfe13158444f6",
            "923a26c2c5a741ddb99f86ccc9149468",
            "5884e4f8237d46abb9a261f9e62b76ab",
            "57b2615fb6f54b0e84d15de56b5bf9de",
            "71caca24574b487eb981015b9dff4286",
            "a332430d3a7e4d43babe9bda054e97bc",
            "ce7c06572e5d4914b235bed3e5e6c206",
            "ba1abed24a794cfe895d4284cbc35be0",
            "fa7d93fe57594b41beacf294708dd94d",
            "03700501af9345ca90c132f76f5bd1c0",
            "e15997fcb85f41bc942914cbb6de191d",
            "b1c1c846f4984094814b75e2f2973c2a",
            "c0210f268724443697181c37bddab26d",
            "01ea7acc6fb94a69896d05606c014750",
            "ae68814953824f9889b791845c35c419",
            "7928d6a010c84e40a670217fe1b00f1d",
            "13b69ae7142d4775acdfa85a848ffc29",
            "99f8a44e1a7f4bdc9a374b6cbfd9a224",
            "36dda90c364b4d42a4beed93c9c7ae22",
            "2cc791baf8bf4783b550807972005b46",
            "a7324146d0b845ddae9ca94bc2c70b44",
            "88502778181f46d895bf450ee59c040d",
            "00ecd01d6bf64b788290b27d38e694af",
            "5f9ba7aafd42470180008a59c9868c14",
            "068bc35e6d4a4ed5ae16f0d9e55f8bff",
            "dbf902c467b446f09e7c413ab16568e2",
            "681eed9a25c04463aeb4ef4c031f083e",
            "3094ed36348c46f4b9ca80e1463b8c3c",
            "575706eaafaf4572b7acf52dd6bd1016",
            "7273f0fdd22b4ca79a40422c6817b197",
            "e30393b8f8974a8aa407d29241b425ce",
            "3859d016ac254ec2aa71017fa502b319",
            "7bb1da18f09a4243902aeb9ba6330cee",
            "89df977dc3e84e30908c559eb6e2c68f",
            "ea790e220439461a84b29f15c54c8b31",
            "606696529db54210a9f2638517450c8c",
            "6f7405d4fc6a4b319ce1817c2bde4640",
            "37a03f3060aa4b539fd46553014200f6",
            "4d070bcc689348cbafd6fddf24738230",
            "1e6a248db1ff471688a25cd480e26c1f",
            "4213e00b1b054ee3b8ed70eb83c41010",
            "8e3080420d794400bcffd58851250c8c",
            "a54d38048ca14e5ba6d1026f5d5e24dc",
            "6baf7738878f4f8ba50c44e5c4cd1357",
            "dad0d5510f044615a918a40e6e8338b9",
            "72d71b990c154302a48c107049bb203e",
            "7f4ec0315f2148ccb6affaa1752259e5",
            "e7485aa5674b4313bf1bd0efddbf31ae",
            "2d24aae3c3d84a879315ed38deafe4c0",
            "f99b48f1bd2446f0b33d7d33b192bfac",
            "c197a2a556b74a43bb094c2418374480",
            "63cc80f7f3f2490dab1c158c7a8e2d0e",
            "5b5199b056464397a62f9748fe8aa966",
            "b0e6f4d083cc4602806191df8d9d4bd7"
          ]
        },
        "id": "0LUqHkMQp0sT",
        "outputId": "ff7486dd-7462-4bbf-8166-92a837771a40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4ad64788b424c35a58d801989813124"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f0df9561efc44b8a7b11ca88b60935a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81274dc6dea043669e193dc1bee572ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d813837fae64d0abe3eb5705b1108f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a2aa298d480467091028bfd137d4efb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90606bb87e024f85aef388757ba549c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fa6df61dc6d4c4ab8a3cf684785dc2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e52e954bb034fb4a9f32c4ea8920ae0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e15997fcb85f41bc942914cbb6de191d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88502778181f46d895bf450ee59c040d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bb1da18f09a4243902aeb9ba6330cee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6baf7738878f4f8ba50c44e5c4cd1357"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Store embeddings in an index database"
      ],
      "metadata": {
        "id": "ZtPvLe8GqUy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have generated embeddings for our text chunks, the next step is to store these embeddings in an **index database**. The index enables efficient similarity search, allowing us to quickly find the most relevant chunks for any query.\n",
        "\n",
        "---\n",
        "\n",
        "### **Why Use an Index Database?**\n",
        "\n",
        "When dealing with a large number of embeddings, searching through them one by one for similarity becomes computationally expensive. By creating an **index**, we can:\n",
        "- **Optimize Search Speed**: Perform nearest neighbor searches in milliseconds, even with millions of embeddings.\n",
        "- **Enable Scalability**: Handle large datasets without performance degradation.\n",
        "- **Support Complex Queries**: Retrieve multiple relevant chunks for a given query.\n",
        "\n",
        "---\n",
        "\n",
        "### **Using FAISS**\n",
        "\n",
        "We use **FAISS (Facebook AI Similarity Search)**, a highly efficient library designed for similarity search tasks. It supports high-dimensional vector data and provides various indexing methods optimized for speed and scalability.\n"
      ],
      "metadata": {
        "id": "3IF-Og1sCYR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import faiss\n",
        "\n",
        "dim = embeds.shape[1]\n",
        "index = faiss.IndexFlatL2(dim)\n",
        "index.add(np.float32(embeds))"
      ],
      "metadata": {
        "id": "7WIJgFkzqLfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Retrieve the relevant information for a query"
      ],
      "metadata": {
        "id": "y7PHtn_2tzgZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With our FAISS index ready, we can now search for the most relevant chunks of text based on a given query. This is the retrieval step in the **Retrieval-Augmented Generation (RAG)** pipeline. It enables us to extract the most contextually relevant information to ground subsequent generation tasks.\n",
        "\n",
        "---\n",
        "\n",
        "### **How It Works**\n",
        "\n",
        "1. **Encode the Query**:\n",
        "   - The query is embedded into the same vector space as the indexed text chunks using the same `SentenceTransformer` model. This ensures that the query and the text chunks can be compared semantically.\n",
        "\n",
        "2. **Search the FAISS Index**:\n",
        "   - The FAISS index is queried to find the nearest neighbors (most similar text chunks) to the query embedding.\n",
        "   - The search returns the indices of the closest embeddings along with their distances (similarity scores).\n",
        "\n",
        "3. **Retrieve and Format Results**:\n",
        "   - The indices are used to fetch the corresponding text chunks.\n",
        "   - The results, including the text and their similarity distances, are stored in a structured DataFrame for easy analysis and use.\n"
      ],
      "metadata": {
        "id": "hIZ64DL6Cvvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(query, number_of_results=3):\n",
        "    \"\"\"\n",
        "    Search for the nearest neighbors of a query in the FAISS index.\n",
        "\n",
        "    Parameters:\n",
        "    - query (str): The query text to search for.\n",
        "    - number_of_results (int): Number of nearest neighbors to retrieve.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: A DataFrame containing the nearest texts and their distances.\n",
        "    \"\"\"\n",
        "    # 1. Get the query's embedding\n",
        "    query_embed = model.encode([query])  # Ensure query is encoded as a list\n",
        "\n",
        "    # 2. Retrieve the nearest neighbors\n",
        "    distances, similar_item_ids = index.search(np.float32(query_embed), number_of_results)\n",
        "\n",
        "    # 3. Format the results\n",
        "    texts_np = np.array(texts)  # Convert texts list to numpy array for indexing\n",
        "    results = pd.DataFrame(data={\n",
        "        'texts': texts_np[similar_item_ids[0]],\n",
        "        'distance': distances[0]\n",
        "    })\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "dwOWv57ZuBye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"which are the executive officers?\"\n",
        "results = retrieve(query)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "jdeii8ultdYJ",
        "outputId": "424448ae-3f39-452a-b789-e7e5bcc5b833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               texts  distance\n",
              "0  This flexibility supports diverse hiring, rete...  1.059170\n",
              "1  B A degree from Harvard Business School Debora...  1.245988\n",
              "2  , a networking equipment company, since 2010 A...  1.306535"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c011a7e-f9fc-4669-8168-9b8efa454f00\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This flexibility supports diverse hiring, rete...</td>\n",
              "      <td>1.059170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B A degree from Harvard Business School Debora...</td>\n",
              "      <td>1.245988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>, a networking equipment company, since 2010 A...</td>\n",
              "      <td>1.306535</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c011a7e-f9fc-4669-8168-9b8efa454f00')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8c011a7e-f9fc-4669-8168-9b8efa454f00 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8c011a7e-f9fc-4669-8168-9b8efa454f00');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-82d83753-473a-4eb7-9dec-b357532632f7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-82d83753-473a-4eb7-9dec-b357532632f7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-82d83753-473a-4eb7-9dec-b357532632f7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2d2ec2b9-448b-437f-9dcc-2c187aef6a27\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2d2ec2b9-448b-437f-9dcc-2c187aef6a27 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"texts\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"This flexibility supports diverse hiring, retention, and employee engagement, which we believe makes NVIDIA a great place to work During fiscal year 2025, we will continue to have a flexible work environment and maintain our company wide 2-days off a quarter for employees to rest and recharge Information About Our Executive Officers The following sets forth certain information regarding our executive officers, their ages, and positions as of February\\u00a016, 2024: Name Age Position Jen-Hsun Huang 60 President and Chief Executive Officer Colette M Kress 56 Executive Vice President and Chief Financial Officer Ajay K Puri 69 Executive Vice President, Worldwide Field Operations Debora Shoquist 69 Executive Vice President, Operations Timothy S Teter 57 Executive Vice President and General Counsel Jen-Hsun Huang co-founded NVIDIA in 1993 and has served as our President, Chief Executive Officer, and a member of the Board of Directors since our inception From 1985 to 1993, Mr Huang was employed at LSI Logic Corporation, a computer chip manufacturer, where he held a variety of positions including as Director of Coreware, the business unit responsible for LSI's SOC From 1983 to 1985, Mr Huang was a microprocessor designer for AMD, a semiconductor company\",\n          \"B A degree from Harvard Business School Debora Shoquist joined NVIDIA in 2007 as Senior Vice President of Operations and in 2009 became Executive Vice President of Operations Prior to NVIDIA, Ms Shoquist served from 2004 to 2007 as Executive Vice President of Operations at JDS Uniphase Corp , a provider of communications test and measurement solutions and optical products for the telecommunications industry She served from 2002 to 2004 as Senior Vice President and General Manager of the Electro-Optics business at Coherent, Inc , a manufacturer of commercial and scientific laser equipment Previously, she worked at Quantum Corp\",\n          \", a networking equipment company, since 2010 At Cisco, Ms Kress was responsible for financial strategy, planning, reporting and business development for all business segments, engineering and operations From 1997 to 2010 Ms Kress held a variety of positions at Microsoft, a software company, including, beginning in 2006, Chief Financial Officer of the Server and Tools division, where Ms Kress was responsible for financial 12 Table of Contents strategy, planning, reporting and business development for the division Prior to joining Microsoft, Ms Kress spent eight years at Texas Instruments Incorporated, a semiconductor company, where she held a variety of finance positions Ms Kress holds a B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"distance\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.059169888496399,\n          1.245988368988037,\n          1.3065346479415894\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results[\"texts\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "Onv7zA5auJTv",
        "outputId": "cb37abfc-aedc-4439-9f97-467db19769d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"This flexibility supports diverse hiring, retention, and employee engagement, which we believe makes NVIDIA a great place to work During fiscal year 2025, we will continue to have a flexible work environment and maintain our company wide 2-days off a quarter for employees to rest and recharge Information About Our Executive Officers The following sets forth certain information regarding our executive officers, their ages, and positions as of February\\xa016, 2024: Name Age Position Jen-Hsun Huang 60 President and Chief Executive Officer Colette M Kress 56 Executive Vice President and Chief Financial Officer Ajay K Puri 69 Executive Vice President, Worldwide Field Operations Debora Shoquist 69 Executive Vice President, Operations Timothy S Teter 57 Executive Vice President and General Counsel Jen-Hsun Huang co-founded NVIDIA in 1993 and has served as our President, Chief Executive Officer, and a member of the Board of Directors since our inception From 1985 to 1993, Mr Huang was employed at LSI Logic Corporation, a computer chip manufacturer, where he held a variety of positions including as Director of Coreware, the business unit responsible for LSI's SOC From 1983 to 1985, Mr Huang was a microprocessor designer for AMD, a semiconductor company\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5. Use an LLM to answer"
      ],
      "metadata": {
        "id": "ms1PaEjC_RJD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final step in our **Retrieval-Augmented Generation (RAG)** pipeline involves utilizing a **Large Language Model (LLM)** to provide a well-grounded answer based on the retrieved text. This step, often referred to as **grounded generation**, ensures that the LLM generates responses that are both contextually accurate and relevant to the query.\n",
        "\n",
        "---\n",
        "\n",
        "### **How It Works**\n",
        "\n",
        "1. **LLM Integration**:\n",
        "   - Use a pre-trained LLM to process the query and the retrieved context.\n",
        "   - Hugging Face’s `pipeline` makes it easy to integrate text-generation models for this purpose.\n",
        "\n",
        "2. **Prompt Design**:\n",
        "   - The LLM is guided by a carefully crafted prompt, which includes:\n",
        "     - **Persona**: Defines the role or expertise of the model.\n",
        "     - **Instruction**: Specifies how the LLM should process the retrieved information.\n",
        "     - **Query**: Combines the user’s question with the retrieved context.\n",
        "\n",
        "3. **Grounded Answering**:\n",
        "   - The LLM generates a response based on the retrieved context.\n",
        "   - If the information is insufficient or unrelated, the LLM is instructed to acknowledge this (e.g., “I am not sure”).\n"
      ],
      "metadata": {
        "id": "3spYlbFdDFTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Create a pipeline\n",
        "pipe = pipeline(\n",
        "    task=\"text-generation\",\n",
        "    model=\"Qwen/Qwen2.5-1.5B-Instruct\",\n",
        "    return_full_text=False,\n",
        "    max_new_tokens=500,\n",
        "    do_sample=True,\n",
        "    temperature=0.2,\n",
        ")"
      ],
      "metadata": {
        "id": "LX85Xy8wuRAz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258,
          "referenced_widgets": [
            "59e112fd526e4b38aa26afc71910671c",
            "586832e7f30342d582ab614bbcc1540e",
            "6d8d7776de4049d5ac0bdff53c2bf475",
            "cd8f5c3b0f564941ac6a79589c4d5b94",
            "16924b3defad443b86adb56a69ae9c30",
            "d485e91b7ac743a0a82f3a984c15eb77",
            "3b657bfcfcd54654bc49dd0df9a2d624",
            "d4513b3013ab41659b9af3d3746fe18a",
            "11aef7975fdc4dc89a4dd5de18c607ff",
            "4c8f9790d97d45c1a721d0a9c6352a49",
            "ab8042e7fa0f4391a16707d7b001fd37",
            "0481102f2a03487d8fda14c0793a5672",
            "ac6d91d7230a4d819f0b43cb8c6963cc",
            "46e2bb200e9c4e9c8744ff46d1cc4341",
            "a0bb9957bd7043e68a9f6cbefa65bc1e",
            "9c3f3b44484c43a790caa8e5b8451fff",
            "4aed561d970c4b43b229ee5e2589921e",
            "41c2725558fc4051a9448908cf64d6cd",
            "93080a2ce677428ba600791bba25cfe0",
            "adf6a64b67374b41a31ae15e551da575",
            "03302bc2c31a479db0ed56cd5fc5bcb4",
            "de4d75a70d674f08b33e70947780cb1e",
            "bc66af86334a4edca422e7db4d177f20",
            "d067a52d23914b099b3ba73d18ec54a4",
            "f1aa0c73a39143b688ee9030b2d7c92b",
            "c94fa8fb97a342c1a6149d367b223eaa",
            "ed40643db58a46438f2ff9a95a4d0cf0",
            "1cc917c11ad94136876508f26b1d0e3d",
            "f3e3f6a86f1f4b458beae86f3b5f0bcf",
            "907887aa72784baa88bc13aa33859dbf",
            "7412fce51cf647b899785ff7b171ce68",
            "b8022163553a4c039db364b761a19b5b",
            "f7bac2d2c98d4c7a8b1ee93abe285a8b",
            "1bfe1cada49e4184bb26a48423946c7a",
            "8f078a795b7c4f27993f0c849f4d3725",
            "ce64b453067f4fb79bd1a263daa10e7b",
            "b24efeef041f41429049eb5f60733bff",
            "dff9e4f2260942a9a1249dc3e5166bb8",
            "0ae3a838ad7946c281cc32cb5745edf8",
            "03561781ab6d4f23945fecbb20de1518",
            "0258d328ab16478f951e4bd7b9ffaa5a",
            "94beff8c454748f6b747d09895127f40",
            "72c3c360eb454da5884554f0ffb769ac",
            "56d01110f4344b4d87544c0b8e6464d1",
            "2a4f42e7b1054eaab2b064a0cfb69161",
            "2e3be0746e8245a784ff5b7bd87952b0",
            "e02dc660b52643eaa7a742b583201da9",
            "7f0e1bdabb69419c8a0b4e1dc638c113",
            "375b87d7036d4829a762f33694102f27",
            "5b5954c39e88417c84382555fbbaa89d",
            "2f19d48d810f4dda89d29de5ed3b22d0",
            "72f3b3ddf3984480aa87d53e3d6f64b4",
            "51f38a73476a433d9ea5bd1f0bc4b734",
            "67f34bd19ae949d4aa3c81a8dfe1141e",
            "369c95b2b10a45a78f219ea7e7b6a792",
            "585e656b71a54101b102816ce14f7a5b",
            "010e313a559f4831b40548731cddfe90",
            "bce67cfcea5044d08f5b964e18ad2737",
            "3ba61157ee5b4595a187de67c033cf05",
            "11a5e656070c43f0852d80ba93244b7f",
            "313efdd2a698404abcb237bc69094801",
            "307d6ea6793944ffb699a71a5f9955b7",
            "f08978c2dd2c454aa3518ca2902df66e",
            "8afe48468c054c98af78512d70cc8e9b",
            "82bdb462495d461d9d4e735f3a6ec589",
            "22c3f171b58a40b7888bc3a77df55e3e",
            "83fded781c114ffab34f4c83d56be9a1",
            "937eb1a95a4a4a46a75f03960375aab1",
            "aa4984c434ad490bb39f871f16bfee94",
            "7045977ad04f4404af4880e5d0197e98",
            "cf904e245aea4c988f27ec9111c57f3f",
            "e9a51613402a47538f3c7977b15b35e0",
            "8cfbae862c5346808f71cca6ba4960f8",
            "7238724f43a84c768b52107119d3563d",
            "2d05ae75bc624a0c8df0e0f5e513cd4a",
            "403e4c7cddcf41ea9394a45ae509fe3e",
            "012d4427fe0a467799a441a66ef62851"
          ]
        },
        "outputId": "3a08d880-989b-4963-daed-a16f82157fdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59e112fd526e4b38aa26afc71910671c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0481102f2a03487d8fda14c0793a5672"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc66af86334a4edca422e7db4d177f20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bfe1cada49e4184bb26a48423946c7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a4f42e7b1054eaab2b064a0cfb69161"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "585e656b71a54101b102816ce14f7a5b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83fded781c114ffab34f4c83d56be9a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt components\n",
        "persona = \"You are a helpful assistant specialized in company annual financial statements.\\n\"\n",
        "instruction = \"Answer using the relevant information provided above. If you didn't find the information say 'I am not sure'.\\n\"\n",
        "\n",
        "# The full prompt - remove and add pieces to view its impact on the generated output\n",
        "llm_query = persona + results[\"texts\"][0]+ instruction + query\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": llm_query}\n",
        "]"
      ],
      "metadata": {
        "id": "B6SBkucQv9xP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = pipe(messages)\n",
        "print(output[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g1SyoK80bCA",
        "outputId": "e7dd675e-a895-4f78-86ea-d5751c976d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The executive officers mentioned in the given text are:\n",
            "\n",
            "1. **Jen-Hsun Huang** - He is described as the President and Chief Executive Officer (CEO) and a member of the Board of Directors since the company's inception.\n",
            "\n",
            "2. **Colette M Kress** - She is listed as the Executive Vice President and Chief Financial Officer.\n",
            "\n",
            "3. **Ajay K Puri** - He is identified as the Executive Vice President, Worldwide Field Operations.\n",
            "\n",
            "4. **Debora Shoquist** - She is named as the Executive Vice President, Operations.\n",
            "\n",
            "5. **Timothy S Teter** - He is referred to as the Executive Vice President and General Counsel.\n",
            "\n",
            "These individuals hold significant roles within NVIDIA and play crucial parts in its operations and leadership.\n"
          ]
        }
      ]
    }
  ]
}